{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9946a5e5",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <span style=\"color:Navy; font-size:200%; font-weight:bold; vertical-align:middle;\">\n",
    "    Temas Selectos: Python para Ciencias de la Tierra\n",
    "  </span>\n",
    "  <img src=\"attachment:logoencit.png\" alt=\"ENCiT\" width=\"150\" style=\"vertical-align:middle; margin-left:20px;\"/>\n",
    "</p>\n",
    "<p align=\"center\" style=\"line-height:1.2;\">\n",
    "  <span style=\"color:RoyalBlue; font-size:160%;\">Tema 4: Introducción al Aprendizaje Automático (Machine Learning) </span><br/>\n",
    "  <span style=\"color:DodgerBlue; font-size:140%;\"> Modelos supervisados: Árboles de desición </span><br/>\n",
    "  <span style=\"font-size:100%;color:forestgreen\"> Escuela Nacional de Ciencias de la Tierra  |  Semestre 2026-I</span>\n",
    "</p>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## **<font color=\"SeaGreen\"> Pronostico de un índice de sequía </font>**\n",
    "\n",
    "A lo largo de esta unidad estaremos construyendo modelos de machine learning para hacer un pronóstico estacional de sequía para un punto en el noroeste de México (lat = 29.725, lon = -109.725).\n",
    "\n",
    "\n",
    "### Paso 0:   Plantear el problema\n",
    "\n",
    "* ¿Cuál es el fenómeno físico que quiero estudiar?\n",
    "    **El comportamiento de la sequía** \n",
    "* ¿Cuál es la variable dependiente?\n",
    "   El SPI (Standardized Precipitation Index) —o Índice Estandarizado de Precipitación— es un indicador estadístico usado para medir las anomalías de precipitación (lluvia) en una región y período determinados. Su objetivo principal es cuantificar las condiciones de sequía o exceso de lluvia de manera estandarizada y comparable en el tiempo y el espacio.\n",
    "\n",
    "    **La variable dependiente sera el SPI de 3 meses (que corresponde a una sequia meteorologica)**\n",
    "\n",
    "* ¿Es una regresión o una clasificación? \n",
    "\n",
    "\n",
    "\n",
    "### Paso 1:  Datos \n",
    "\n",
    "* Obtener información diversa (¿Necesitamos muchos datos?).\n",
    "\n",
    "    ¿Existen datos confiables que pueda usar?\n",
    "    ¿Los datos tienen variedad?\n",
    "\n",
    "* Remover información falsa, buscar/llenar valores faltantes… \n",
    "\n",
    "    Si no lleno los vacíos, el molodelo los aprenderá también.\n",
    "\n",
    "  \n",
    "### Paso 2:  Variables predictoras \n",
    "* Proponer variables “predictoras” \n",
    "\n",
    "* **Hacer un análisis estadístico de las variables propuestas.**\n",
    "\n",
    "* Definir las variables de entrada.\n",
    "\n",
    "\n",
    "> Las variables que estan relacionadas con las sequías son aquellas que afectan al ciclo hidrológico y que pueden causar un estrés hídrico. Una alteración en estas variables detonan reacciones en cadena conocidas como procesos de retroalimentación.\n",
    "\n",
    "Las variables que se proponen (inicialmente) para hacer los modelos, y sus procedencias, son las siguientes:\n",
    "\n",
    "\n",
    "|Variable                                     | Abreviacion  | Base de datos  |\n",
    "|---------------------------------------------|--------------|----------------|\n",
    "|Precipitación acumulada                      | pcp          | CHIRPS         |\n",
    "|Radiación de onda larga saliente             | OLR          | NCEP-NCAR      |\n",
    "|SSTs en la región de El Niño 3.4             | SST          | NOAA           |\n",
    "|Volumen de agua en la primera capa del suelo | swvl1        | ERA-5 Land     |\n",
    "|Temperatura en la superficie del suelo       | skt          | ERA-5 Land     |\n",
    "|Altura geopotencial en 600mb                 | hgt          | NCEP-NCAR      |\n",
    "\n",
    "\n",
    "### Paso 3:  Dividir la base de datos en 2 o 3 subcategorías \n",
    "* 70-85% para entrenar el modelo \n",
    "\n",
    "* 5-15% para validar/evaluar el modelo\n",
    "\n",
    "* Probar el modelo\n",
    "\n",
    "\n",
    "### Paso 4: Implementar el/los modelos disponibles.\n",
    "Entrenar los modelos puede ser una tarea sencilla, pero hay que considerar ciertos parámetros (e hiperparámetros):\t\n",
    "* La función de costo\n",
    "* El tipo de entrenamiento \n",
    "* La tasa de aprendizaje \n",
    "\n",
    "### Paso 5: Paso 5: Evaluación de modelos. \n",
    "Se debe evaluar los modelos tanto con los datos de entrenamiento como con los datos de prueba. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4117ec-71aa-4ee7-b852-42e2b7b69c81",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Pasos 2 al 5 : <b> La misión en esta clase será implementar modelos de Redes Neuronales Artificiales para tareas regresivas y de clasificación.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46e3436-109a-4ac3-9a5b-84026ed64e01",
   "metadata": {},
   "source": [
    "### **<font color=\"SeaGreen\"> Importar la base de datos </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8711b324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import sklearn\n",
    "#from sklearn.neighbors import LocalOutlierFactor\n",
    "#from scipy.spatial.distance import mahalanobis\n",
    "#from scipy.stats import chi2\n",
    "#import scipy.cluster.hierarchy as sch\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "#from sklearn.svm import LinearSVR\n",
    "#from sklearn.svm import SVC\n",
    "\n",
    "#from sklearn.ensemble import ExtraTreesRegressor,ExtraTreesClassifier\n",
    "#from sklearn.tree import plot_tree\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor,MLPClassifier\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ba82d5-c81e-4edd-8418-d67bf56a5ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# carga de archivo csv\n",
    "df=pd.read_csv('sequias_datos.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450c093c-502e-486d-9912-b83b6f3e6a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "VariablesNumAnalis = [ 'spi', 'sst_mean_DJF', 'pcp_DJF', 'hgt_DJF', 'olr_DJF', 'skt_DJF', 'swvl1_DJF']\n",
    "\n",
    "df_DEF = df[VariablesNumAnalis]\n",
    "df_DEF.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "21c759cc",
   "metadata": {},
   "source": [
    "### **<font color=\"SeaGreen\"> Paso 2:  Variables predictoras  </font>**\n",
    "\n",
    "En las clases pasadas hemos estado haciendo el análisis multivariado de los datos. Estos nos ha permitido saber cuáles son las variables con mayor potencial de funcionar para nuestros modelos. \n",
    "¿Recuerdan cuáles son? \n",
    "\n",
    "![spearman.png](spearman.png)\n",
    "![pca.png](pca.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa87e94-7543-44f0-a24a-fff1c3f148f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a crear varios modelos para ver cuál es mejor. \n",
    "\n",
    "# Primero, vamos a separar la variable de los años \n",
    "anios = df[['Year']].copy()\n",
    "\n",
    "# Ahora vamos a proponer el primer modelo con un solo predictor\n",
    "x_prep_1 = df_DEF[['pcp_DJF','olr_DJF','swvl1_DJF']].copy()\n",
    "\n",
    "x_prep_3 = df_DEF[['pcp_DJF','hgt_DJF', 'olr_DJF']].copy()\n",
    " \n",
    "# Separamos la variable dependiente\n",
    "y = df[['spi']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2132391c-2cb8-4c82-95e1-c1bb47259797",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escalamos los datos\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_scaled_1 = scaler.fit_transform(x_prep_1)\n",
    "x1_scaled_df = pd.DataFrame(x_scaled_1, columns=x_prep_1.columns)\n",
    "\n",
    "x_scaled_3 = scaler.fit_transform(x_prep_3)\n",
    "x3_scaled_df = pd.DataFrame(x_scaled_3, columns=x_prep_3.columns)\n",
    "\n",
    "y_df_anios = y.copy()\n",
    "y_df_anios['Year'] = anios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8207cf4-f8de-4bac-9efa-e955298e97c4",
   "metadata": {},
   "source": [
    "### **<font color=\"SeaGreen\"> Paso 3:  Dividir la base de datos en 2 o 3 subcategorías  </font>**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e2b745-46ef-49ba-9b6e-5de589b32670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora hacemos la division de los datos \n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(x1_scaled_df, y, test_size=0.35, random_state=43)\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(x3_scaled_df, y, test_size=0.35, random_state=43)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44bad32-980e-471a-a350-ea3f2cb5e7b2",
   "metadata": {},
   "source": [
    "### **<font color=\"SeaGreen\"> Paso 4: Implementar el/los modelos disponibles. </font>**\n",
    "\n",
    "Hoy vamos a usar árboles de desición para tareas regresivas y máquinas de soporte vectorial para clasificación.\n",
    "\n",
    "Para mas informacion sobre los árboles de desición: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html\n",
    "\n",
    "\n",
    "`class sklearn.neural_network.MLPRegressor(loss='squared_error', hidden_layer_sizes=(100,), activation='relu', *, solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18033ad1-38a4-40fc-8d43-bf9dd699ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el modelo\n",
    "ann1 = MLPRegressor(hidden_layer_sizes=(150,150,150), activation='identity', solver='sgd', max_iter=1500, random_state =19000, learning_rate='adaptive',shuffle=True)\n",
    "# Entrenamos el modelo\n",
    "ann1.fit(X_train1,y_train1.values.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92272c65-bff5-49cb-8e75-8741c42db921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora ustedes creen las predicciones para el conjunto de prueba y entrenamiento\n",
    "\n",
    "# Predicciones con el conjunto de datos de entrenamiento\n",
    "y1_pred_train = _______________________\n",
    "\n",
    "# Predicciones con el conjunto de datos de prueba\n",
    "y1_pred_test = ________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e29d6f-625c-44af-a825-69d8a7ed50e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creen el modelo para el segundo conjunto de predictores con los mismos hiperparametros que el anterior \n",
    "# Es decir, tres capas escondidas con 150 perceptrones en cada una, funcion de activacion identity, solver sgd, \n",
    "# numero maximo de iteraciones 1500, random state 19000, learning rate adaptive y con el suffle activado. \n",
    "\n",
    "ann3 = _______________________\n",
    "\n",
    "#Ahora ajusten el modelo\n",
    "\n",
    "\n",
    "__________________________\n",
    "\n",
    "#creen las predicciones \n",
    "\n",
    "# Predicciones con el conjunto de datos de entrenamiento\n",
    "y3_pred_train = ______________________________\n",
    "    \n",
    "# Predicciones con el conjunto de datos de prueba\n",
    "y3_pred_test = ______________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3007da94-5ff8-434a-aaf4-1d9b731d291b",
   "metadata": {},
   "source": [
    "### **<font color=\"SeaGreen\"> Paso 5: Evaluación de modelos. </font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b789508b-fb29-4b0b-aa1f-3ce7d3d8044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos un DataFrame para ir guardando las evaluaciones de los modelos\n",
    "\n",
    "perf_index={'predictores':[],'R2':[],'MSE':[]}\n",
    "ML_method=[]\n",
    "df_pi=pd.DataFrame(perf_index, index=ML_method)\n",
    "df_pi = df_pi.rename_axis('ML methods')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5bd1f7-d398-49fb-909d-8fe1a0353e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "y1_pred_train_df = pd.DataFrame(y1_pred_train,columns=['spi_train_predicted'])\n",
    "y1_pred_test_df = pd.DataFrame(y1_pred_test, columns=['spi_test_predicted'])\n",
    "\n",
    "#Evaluacion con el conjunto de datos de entrenamiento \n",
    "r2_score_train1 = metrics.r2_score(y_train1,y1_pred_train_df)\n",
    "mean_squared_error_train1 = metrics.mean_squared_error(y_train1,y1_pred_train_df)\n",
    "row_list=[', '.join(x1_scaled_df.columns),r2_score_train1,mean_squared_error_train1]\n",
    "df_pi.loc['ANN entrenamiento 1']=row_list\n",
    "\n",
    "#Evaluacion con el conjunto de datos de prueba\n",
    "r2_score_test1 = metrics.r2_score(y_test1,y1_pred_test_df)\n",
    "mean_squared_error_test1 = metrics.mean_squared_error(y_test1,y1_pred_test_df)\n",
    "\n",
    "row_list=[', '.join(x_prep_1.columns),r2_score_test1,mean_squared_error_test1]\n",
    "df_pi.loc['ANN prueba 1']=row_list\n",
    "print(df_pi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f4fba6-ce6d-4888-8f7f-aea9a00710a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted_vs_observed_train1 = y1_pred_train_df.copy()\n",
    "df_predicted_vs_observed_train1['spi_observed'] = y_train1.copy()\n",
    "\n",
    "plt.figure()\n",
    "sns.scatterplot(x='spi_train_predicted', y='spi_observed', data = df_predicted_vs_observed_train1)\n",
    "plt.plot([df_predicted_vs_observed_train1.min().min(), df_predicted_vs_observed_train1.max().max()],\n",
    "         [df_predicted_vs_observed_train1.min().min(), df_predicted_vs_observed_train1.max().max()],\n",
    "         linestyle='--', color='red')\n",
    "plt.xlabel('spi predicho')\n",
    "plt.ylabel('spi observado')\n",
    "plt.title('SPI predicho vs observado con datos de entrenamiento y pcp_DJF, olr_DJF, swvl1_DJF')\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc62e84-8d5a-4bac-ae21-12ae5b72dc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted_vs_observed_test1 = y1_pred_test_df.copy()\n",
    "df_predicted_vs_observed_test1['spi_observed'] = y_test1.copy()\n",
    "\n",
    "plt.figure()\n",
    "sns.scatterplot(x='spi_test_predicted', y='spi_observed', data = df_predicted_vs_observed_test1)\n",
    "plt.plot([df_predicted_vs_observed_test1.min().min(), df_predicted_vs_observed_test1.max().max()],\n",
    "         [df_predicted_vs_observed_test1.min().min(), df_predicted_vs_observed_test1.max().max()],\n",
    "         linestyle='--', color='red')\n",
    "plt.xlabel('spi predicho')\n",
    "plt.ylabel('spi observado')\n",
    "plt.title('SPI predicho vs observado con datos de prueba y pcp_DJF, olr_DJF, swvl1_DJF')\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d10596-57ef-4cf3-bf3a-880c2ce6fa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar predicciones con los años correspondientes\n",
    "df_train_pred_rl1 = pd.DataFrame({'Year': X_train1.index.map(lambda i: y_df_anios.loc[i, 'Year']),\n",
    "                              'spi_predicted': y1_pred_train_df.squeeze()})\n",
    "\n",
    "df_test_pred_rl1 = pd.DataFrame({'Year': X_test1.index.map(lambda i: y_df_anios.loc[i, 'Year']),\n",
    "                             'spi_predicted': y1_pred_test_df.squeeze()})\n",
    "\n",
    "# Unir todo y ordenar cronológicamente\n",
    "df_pred_total_rn1 = pd.concat([df_train_pred_rl1, df_test_pred_rl1])\n",
    "df_pred_total_rn1 = df_pred_total_rn1.sort_values('Year').reset_index(drop=True)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(df['Year'], df['spi'], label='Observado', marker='o')\n",
    "#sns.lineplot(x='Year',y='spi', data=df, markers='o')\n",
    "plt.plot(df_pred_total_rn1['Year'], df_pred_total_rn1['spi_predicted'], label='Predicho AD pcp_DJF, olr_DJF, swvl1_DJF', marker='s')\n",
    "plt.legend()\n",
    "plt.xlabel('Año')\n",
    "plt.ylabel('SPI')\n",
    "plt.title('Serie temporal observada vs predicha')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8356a27d-b8da-4fb1-b633-74c4ba686e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y3_pred_train_df = pd.DataFrame(y3_pred_train,columns=['spi_train_predicted'])\n",
    "y3_pred_test_df = pd.DataFrame(y3_pred_test, columns=['spi_test_predicted'])\n",
    "\n",
    "#Evaluacion con el conjunto de datos de entrenamiento \n",
    "r2_score_train3 = metrics.r2_score(y_train3,y3_pred_train_df)\n",
    "mean_squared_error_train3 = metrics.mean_squared_error(y_train3,y3_pred_train_df)\n",
    "row_list=[', '.join(x_prep_3.columns),r2_score_train3,mean_squared_error_train3]\n",
    "df_pi.loc['ANN entrenamiento 3']=row_list\n",
    "\n",
    "#Evaluacion con el conjunto de datos de prueba\n",
    "r2_score_test3 = metrics.r2_score(y_test3,y3_pred_test_df)\n",
    "mean_squared_error_test3 = metrics.mean_squared_error(y_test3,y3_pred_test_df)\n",
    "\n",
    "row_list=[', '.join(x_prep_3.columns),r2_score_test3,mean_squared_error_test3]\n",
    "df_pi.loc['ANN prueba 3']=row_list\n",
    "print(df_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9bf124-b203-481a-8af3-c715591d5e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted_vs_observed_train3 = y3_pred_train_df.copy()\n",
    "df_predicted_vs_observed_train3['spi_observed'] = y_train3.copy()\n",
    "\n",
    "plt.figure()\n",
    "sns.scatterplot(x='spi_train_predicted', y='spi_observed', data = df_predicted_vs_observed_train3)\n",
    "plt.plot([df_predicted_vs_observed_train3.min().min(), df_predicted_vs_observed_train3.max().max()],\n",
    "         [df_predicted_vs_observed_train3.min().min(), df_predicted_vs_observed_train3.max().max()],\n",
    "         linestyle='--', color='red')\n",
    "plt.xlabel('spi predicho')\n",
    "plt.ylabel('spi observado')\n",
    "plt.title('SPI predicho vs observado con datos de entrenamiento y pcp_DJF, hgt_DJF, olr_DJF')\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0c65cf-c8e2-40d6-a64c-6138994a95eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicted_vs_observed_test3 = y3_pred_test_df.copy()\n",
    "df_predicted_vs_observed_test3['spi_observed'] = y_test3.copy()\n",
    "\n",
    "plt.figure()\n",
    "sns.scatterplot(x='spi_test_predicted', y='spi_observed', data = df_predicted_vs_observed_test3)\n",
    "plt.plot([df_predicted_vs_observed_test3.min().min(), df_predicted_vs_observed_test3.max().max()],\n",
    "         [df_predicted_vs_observed_test3.min().min(), df_predicted_vs_observed_test3.max().max()],\n",
    "         linestyle='--', color='red')\n",
    "plt.xlabel('spi predicho')\n",
    "plt.ylabel('spi observado')\n",
    "plt.title('SPI predicho vs observado con datos de prueba y pcp_DJF, hgt_DJF, olr_DJF')\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac31eba5-1f43-4ea1-a806-267e935e7139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar predicciones con los años correspondientes\n",
    "df_train_pred_rl3 = pd.DataFrame({'Year': X_train3.index.map(lambda i: y_df_anios.loc[i, 'Year']),\n",
    "                              'spi_predicted': y3_pred_train_df.squeeze()})\n",
    "\n",
    "df_test_pred_rl3 = pd.DataFrame({'Year': X_test3.index.map(lambda i: y_df_anios.loc[i, 'Year']),\n",
    "                             'spi_predicted': y2_pred_test_df.squeeze()})\n",
    "\n",
    "# Unir todo y ordenar cronológicamente\n",
    "df_pred_total_rn3 = pd.concat([df_train_pred_rl3, df_test_pred_rl3])\n",
    "df_pred_total_rn3 = df_pred_total_rn3.sort_values('Year').reset_index(drop=True)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(df['Year'], df['spi'], label='Observado', marker='o')\n",
    "#sns.lineplot(x='Year',y='spi', data=df, markers='o')\n",
    "plt.plot(df_pred_total_rn1['Year'], df_pred_total_rn1['spi_predicted'], label='Predicho ANN pcp_DJF, olr_DJF, swvl1_DJF', marker='s')\n",
    "plt.plot(df_pred_total_rn2['Year'], df_pred_total_rn2['spi_predicted'], label='Predicho ANN hgt_DJF, skt_DJF, sst_mean_DJF', marker='s')\n",
    "plt.plot(df_pred_total_rn3['Year'], df_pred_total_rn3['spi_predicted'], label='Predicho ANN pcp_DJF, hgt_DJF, olr_DJF', marker='s')\n",
    "plt.legend()\n",
    "plt.xlabel('Año')\n",
    "plt.ylabel('SPI')\n",
    "plt.title('Serie temporal observada vs predicha')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74fb1d2-0f61-491f-8cd4-a93415a25eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ff6b35",
   "metadata": {},
   "source": [
    "### **<font color=\"SeaGreen\"> Paso 4: Implementar el/los modelos disponibles. </font>**\n",
    "\n",
    "\n",
    "Para los árboles de decisión clasificatorias: https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html\n",
    "\n",
    "\n",
    "\n",
    "`class sklearn.neural_network.MLPClassifier(hidden_layer_sizes=(100,), activation='relu', *, solver='adam', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c79702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para implementar las maquinas de soporte vectorial para clasificacion, \n",
    "# primero vamos a crear una etiqueda de salida.\n",
    "\n",
    "def categorizar_spi(spi):\n",
    "    if spi <= -0.5 : \n",
    "        return 'sequia'\n",
    "    else:\n",
    "        return 'sin_sequia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae77c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sequia'] = df['spi'].apply(categorizar_spi)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4f158d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sequia'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dee226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos nuestra variable dependiente para categorizar.\n",
    "\n",
    "y_cat = df[['sequia']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b96ee0c-6b44-4bb6-ac59-94b8b83e9aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crea los conjuntos de entrenamiento (65%) y de prueba (35%) con un random state de 43 .\n",
    "X_train1c, X_test1c, y_train1c, y_test1c =\n",
    "\n",
    "X_train3c, X_test3c, y_train3c, y_test3c ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b4566e-db8f-4b04-8a61-0857658046df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrena una red neuronal articificial con tres capas escondidas con 150 perceptrones en cada una, \n",
    "#funcion de activacion identity, solver sgd, numero maximo de iteraciones 1500, random state 19000, \n",
    "# learning rate adaptive y con el suffle activado. \n",
    "\n",
    "#Crea el modelo\n",
    "annc1 =  MLPClassifier()\n",
    "\n",
    "#Entrena el modelo \n",
    "_______________________________\n",
    "\n",
    "#Crea las predicciones\n",
    "yc1_pred_train = _______________________\n",
    "yc1_pred_test = _______________________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8727381c-006a-4efb-a4cb-721a6c1914b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora crea el segundo modelo \n",
    "\n",
    "#Crea el modelo\n",
    "annc3 =  MLPClassifier()\n",
    "\n",
    "#Entrena el modelo \n",
    "_______________________________\n",
    "\n",
    "#Crea las predicciones\n",
    "yc3_pred_train = _______________________\n",
    "yc3_pred_test = _______________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f5a44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_index={'predictores':[],'f1':[],'falsas alarmas':[]}\n",
    "ML_method=[]\n",
    "df_pic=pd.DataFrame(perf_index, index=ML_method)\n",
    "df_pic = df_pic.rename_axis('ML methods')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2186ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "yc1_pred_train_df = pd.DataFrame(yc1_pred_train,columns=['sequia_pred'])\n",
    "yc1_pred_test_df = pd.DataFrame(yc1_pred_test,columns=['sequia_pred'])\n",
    "\n",
    "Etiquetas = ['sequia','sin_sequia']\n",
    "confusion_1_train = confusion_matrix(y_train1c['sequia'],yc1_pred_train_df['sequia_pred'])\n",
    "ConfusionMatrixDisplay(confusion_matrix=confusion_1_train, display_labels=Etiquetas).plot()\n",
    "\n",
    "f1_score_train1 = f1_score(yc1_pred_train_df['sequia_pred'], y_train1c['sequia'],pos_label='sequia')\n",
    "precision_train1 = precision_score(yc1_pred_train_df['sequia_pred'], y_train1c['sequia'],pos_label='sequia')\n",
    "\n",
    "row_list=[', '.join(x_prep_1.columns),f1_score_train1,precision_train1]\n",
    "df_pic.loc['ANNC entrenamiento 1']=row_list\n",
    "\n",
    "confusion_1_test = confusion_matrix(y_test1c['sequia'],yc1_pred_test_df['sequia_pred'])\n",
    "ConfusionMatrixDisplay(confusion_matrix=confusion_1_test, display_labels=Etiquetas).plot()\n",
    "\n",
    "f1_score_test1 = f1_score(yc1_pred_test_df['sequia_pred'], y_test1c['sequia'],pos_label='sequia')\n",
    "precision_test1 = precision_score(yc1_pred_test_df['sequia_pred'], y_test1c['sequia'],pos_label='sequia')\n",
    "\n",
    "row_list=[', '.join(x_prep_1.columns),f1_score_test1,precision_test1]\n",
    "df_pic.loc['ANNC prueba 1']=row_list\n",
    "print(df_pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8900572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yc3_pred_train_df = pd.DataFrame(yc3_pred_train,columns=['sequia_pred'])\n",
    "yc3_pred_test_df = pd.DataFrame(yc3_pred_test,columns=['sequia_pred'])\n",
    "\n",
    "Etiquetas = ['sequia','sin_sequia']\n",
    "confusion_3_train = confusion_matrix(y_train3c['sequia'],yc3_pred_train_df['sequia_pred'])\n",
    "ConfusionMatrixDisplay(confusion_matrix=confusion_3_train, display_labels=Etiquetas).plot()\n",
    "\n",
    "f1_score_train3 = f1_score(yc3_pred_train_df['sequia_pred'], y_train3c['sequia'],pos_label='sequia')\n",
    "precision_train3 = precision_score(yc3_pred_train_df['sequia_pred'], y_train3c['sequia'],pos_label='sequia')\n",
    "\n",
    "row_list=[', '.join(x_prep_3.columns),f1_score_train3,precision_train3]\n",
    "df_pic.loc['ANNC entrenamiento 3']=row_list\n",
    "\n",
    "\n",
    "confusion_3_test = confusion_matrix(y_test3c['sequia'],yc3_pred_test_df['sequia_pred'])\n",
    "ConfusionMatrixDisplay(confusion_matrix=confusion_3_test, display_labels=Etiquetas).plot()\n",
    "\n",
    "f1_score_test3 = f1_score(yc3_pred_test_df['sequia_pred'], y_test3c['sequia'],pos_label='sequia')\n",
    "precision_test3 = precision_score(yc3_pred_test_df['sequia_pred'], y_test3c['sequia'],pos_label='sequia')\n",
    "\n",
    "row_list=[', '.join(x_prep_3.columns),f1_score_test3,precision_test3]\n",
    "df_pic.loc['ANNC prueba 3']=row_list\n",
    "print(df_pic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7bb22e-900b-4110-ad3e-d720df1ad0ec",
   "metadata": {},
   "source": [
    "---\n",
    "<a name='ej-1'></a>\n",
    "### **<font color=\"DodgerBlue\"> Ejercicio 1 :   </font>**\n",
    "\n",
    "<font color=\"DarkBlue\">  Obten el modelo de ANN regresiva del PM10 de 5 horas despues considerando las variables predictoras más importantes (usando la temperatura promedio, la humedad relativa y el PM2.5). Despues, crea la categorizacion de la calidad del aire, si el PM10 es mayor o igual a 35 ppm, es mala, en otro caso es buena. Luego, crea el modelo de ANN categorica. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ac960f-d151-4c6e-8616-51f1dbdb3027",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>Nota: <b> En este caso tambien deben estandarizar la variable dependiente (PM10), y despues de hacer las predicciones, deben des-estandarizar los datos `.inverse_transform(.reshape(-1, 1))`\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2713d42e-712b-4b55-a66c-6b9e3254ad97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
